---
title: "MySQL性能分析及优化"
subtitle: ""
layout: post
author: "Aug"
header-style: text
tags:
  - MySQL
---

# 性能分析

## 慢查询日志

> 会列出超过指定阈值的sql语句。默认关闭，需手动开启

### 永久开启慢查询日志

```mysql
slow_query_log = 1 # 开启慢查询日志 
slow_query_log_file = /var/lib/mysql/slow.log  # 日志存储位置
long_query_time = 1 # 大于等于该时间(秒)
```

### 慢查询日志工具

#### mysqldumpslow 

> mysql自带

得到按照时间排序的前10条里面含有左连接的查询语句: 

```mysql
[root@localhost mysql]# mysqldumpslow -s t -t 10 -g “left join” /var/log/mysql/slow.log
```

参数说明：

-s:是表示按照何种方式排序

​	c：访问次数

​	l：锁定时间

​	r：返回记录

​	t：查询时间

​	al：平均锁定时间

​	ar：平均返回记录数

​	at：平均查询时间

-t:是top n的意思，即为返回前面多少条的数据

-g:后边可以写一个正则匹配模式，大小写不敏感的

#### percona-toolkit

> percona-toolkit是一组高级命令行工具的集合，可以查看当前服务的摘要信息，磁盘检测，分析慢查询日志，查找重 复索引，实现表同步等等

- 下载：

```shell
wget https://www.percona.com/downloads/percona-toolkit/3.0.11/binary/tarball/percona-
toolkit-3.0.11_x86_64.tar.gz
```

- 安装：

```shell
tar -xf percona-toolkit-3.0.11_x86_64.tar.gz
cd percona-toolkit-3.0.11
perl Makefile.PL
make
make install
```

- 错误解决方式：

Can't locate ExtUtils/MakeMaker.pm in @INC

```shell
yum install -y perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker
```

Can't locate Time/HiRes.pm in @INC

```shell
yum install -y perl-Time-HiRes
```

Can't locate Digest/MD5.pm in @INC

```shell
yum install perl-Digest-MD5.x86_64
```

- 使用pt-query-digest查看慢查询日志：

```shell
pt-query-digest /var/lib/mysql/localhost-slow.log
```

**pt-query-digest语法及重要选项**

```shell
pt-query-digest [OPTIONS] [FILES] [DSN]
--create-review-table 当使用--review参数把分析结果输出到表中时，如果没有表就自动创建。 --create-history-table 当使用--history参数把分析结果输出到表中时，如果没有表就自动创建。 --filter 对输入的慢查询按指定的字符串进行匹配过滤后再进行分析
--limit 限制输出结果百分比或数量，默认值是20,即将最慢的20条语句输出，如果是50%则按总响应时 间占比从大到小排序，输出到总和达到50%位置截止。
--host mysql服务器地址
--user mysql用户名
--password mysql用户密码
--history 将分析结果保存到表中，分析结果比较详细，下次再使用--history时，如果存在相同的语句， 且查询所在的时间区间和历史表中的不同，则会记录到数据表中，可以通过查询同一CHECKSUM来比较某类型 查询的历史变化。
--review 将分析结果保存到表中，这个分析只是对查询条件进行参数化，一个类型的查询一条记录，比较简 单。当下次使用--review时，如果存在相同的语句分析，就不会记录到数据表中。
--output 分析结果输出类型，值可以是report(标准分析报告)、slowlog(Mysql slow log)、 json、json-anon，一般使用report，以便于阅读。
--since 从什么时间开始分析，值为字符串，可以是指定的某个”yyyy-mm-dd [hh:mm:ss]”格式的时间 点，也可以是简单的一个时间值:s(秒)、h(小时)、m(分钟)、d(天)，如12h就表示从12小时前开始统计。 --until 截止时间，配合—since可以分析一段时间内的慢查询。
```

**分析pt-query-digest输出结果**

- 第一部分:总体统计结果 Overall:总共有多少条查询 Time range:查询执行的时间范围 unique:唯一查询数量，即对查询条件进行参数化以后，总共有多少个不同的查询 total:总计 min:最小 max:最大 avg:平均 95%:把所有值从小到大排列，位置位于95%的那个数，这个 数一般最具有参考价值 median:中位数，把所有值从小到大排列，位置位于中间那个数 
- 第二部分:查询分组统计结果 Rank:所有语句的排名，默认按查询时间降序排列，通过--order- by指定 Query ID:语句的ID，(去掉多余空格和文本字符，计算hash值) Response:总的响应 时间 time:该查询在本次分析中总的时间占比 calls:执行次数，即本次分析总共有多少条这种类 型的查询语句 R/Call:平均每次执行的响应时间 V/M:响应时间Variance-to-mean的比率 Item: 查询对象 
- 第三部分:每一种查询的详细统计结果 由下面查询的详细统计结果，最上面的表格列出了执行次 数、最大、最小、平均、95%等各项目的统计。 ID:查询的ID号，和上图的Query ID对应 Databases:数据库名 Users:各个用户执行的次数(占比) Query_time distribution :查询时 间分布, 长短体现区间占比，本例中1s-10s之间查询数量是10s以上的两倍。 Tables:查询中涉及 到的表 Explain:SQL语句 


- 用法示例：
  
  1. 直接分析慢查询文件: 
  ```shell
  pt-query-digest  slow.log > slow_report.log
  ```
  2. 分析最近12小时内的查询:
  ```shell
  pt-query-digest --since=12h slow.log > slow_report2.log
  ```
  3. 分析指定时间范围内的查询: 
  ```shell
  pt-query-digest slow.log --since '2017-01-07 09:30:00' --until '2017-01-07 10:00:00'> >
  slow_report3.log
  ```
  4. 分析指含有select语句的慢查询
  ```shell
  pt-query-digest --filter '$event->{fingerprint} =~ m/^select/i' slow.log> slow_report4.log
  ```
  5. 针对某个用户的慢查询
  ```shell
  pt-query-digest --filter '($event->{user} || "") =~ m/^root/i' slow.log> slow_report5.log
  ```
  6. 查询所有所有的全表扫描或full join的慢查询 
  ```shell
  pt-query-digest --filter '(($event->{Full_scan} || "") eq "yes") ||(($event->{Full_join} ||
  "") eq "yes")' slow.log> slow_report6.log
  ```
  7. 把查询保存到query_review表 
  ```shell
  pt-query-digest --user=root –password=abc123 --review  h=localhost,D=test,t=query_review--
  create-review-table  slow.log
  ```
  8. 把查询保存到query_history表 
  ```shell
  pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_history--
  create-review-table  slow.log_0001
  pt-query-digest  --user=root –password=abc123 --review  h=localhost,D=test,t=query_history--
  create-review-table  slow.log_0002
  ```
  9. 通过tcpdump抓取mysql的tcp协议数据，然后再分析 
  ```shell
  tcpdump -s 65535 -x -nn -q -tttt -i any -c 1000 port 3306 > mysql.tcp.txt
  pt-query-digest --type tcpdump mysql.tcp.txt> slow_report9.log
  ```
  ```
  10. 分析binlog 
​```shell
  mysqlbinlog mysql-bin.000093 > mysql-bin000093.sql
  pt-query-digest  --type=binlog  mysql-bin000093.sql > slow_report10.log
  ```
  11. 分析general log 
  ```shell
  pt-query-digest  --type=genlog  localhost.log > slow_report11.log
  ```

## profile语句分析

> MySQL自带的一种query诊断分析工具，通过它可以分析出一条SQL语句的硬件性能瓶颈在什么地方。通常我们是使用的explain,以及slow query log都无法做到精确分析，但是Query Profiler却可以定位出一条SQL语 句执行的各种资源消耗情况，比如CPU，IO等，以及该SQL执行所耗费的时间等。不过该工具只有在MySQL 5.0.37 以及以上版本中才有实现。
>
> 默认关闭，需手动启动

### 语句使用

- show profile 和 show profiles 语句可以展示当前会话(退出session后,profiling重置为0) 中执行语句的资源使 用情况
- show profiles :以列表形式显示最近发送到服务器上执行的语句的资源使用情况.显示的记录数由变量:profiling_history_size 控制,默认15条
- show profile: 展示最近一条语句执行的详细资源占用信息,默认显示 Status和Duration两列

### 开启profile

- Profile 功能由MySQL会话变量profiling控制,默认是OFF关闭状态

- 查看是否开启了Profile功能

  ```mysql
  select @@profiling;
  show variables like ‘%profil%’;
  ```

- 开启profile功能

  ```mysql
  set profiling=1; --1是开启、0是关闭
  ```



# 性能优化

## 硬件层面优化

### 内存读取

设置足够大的 **innodb_buffer_pool_size** ，将数据读取到内存中 

> innodb_buffer_pool_size默认128M，建议设置为总内存大小的75%或80%

### 内存预热

将磁盘数据在mysql server启动的时候，读取到内存中

### 降低磁盘写入次数

- 生产环境中很多日志不需要开启，例如：通用查询日志、慢查询日志、错误日志

- 使用足够大的写缓存**innodb_log_file_size**

  > 建议设置为**innodb_buffer_pool_size**的25%

- 设置合适的**innodb_flush_log_at_trx_commit**，合理落盘 

### 提高磁盘读写

使用SSD



## sql设计层面优化

- 设计中间表 
- 创建合理的冗余字段 
- 分库分表
- 合理主键



## sql语句优化

### 索引优化

- 为条件字段、排序字段创建合适的索引
- 组合索引
- 索引下推
- 覆盖索引
- 不要用*

### limit优化

如果预计SELECT语句的查询结果是一条，最好使用LIMIT 1，可以停止全表扫描

### 其它优化

- count (*) 找普通索引 包含空值
- count(字段) 走缓存 不包含空值
- count(1) 忽略字段 包含空值
- 不用mysql内置函数，内置函数不会建立查询缓存，可以上浮到业务逻辑中处理



# 测试

建表并插入1000万条数据

```mysql
CREATE PROCEDURE test_insert()
BEGIN
DECLARE i INT DEFAULT 1;
WHILE i<=10000000
DO
insert into tuser2
VALUES(null,concat('zy',i),concat('zhaoyun',i),23,'1',1,'beijing');
SET i=i+1;
END WHILE ;
commit;
END;
 
```


