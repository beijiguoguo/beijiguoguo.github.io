---
title: "Java并发相关常见面试题"
subtitle: ""
layout: post
author: "Aug"
header-style: text
tags:
  - 面试
---


**1、synchronized的实现原理以及锁优化？**

https://nicky-chen.github.io/2018/05/14/synchronized-principle/

**2、volatile的实现原理？**

https://nicky-chen.github.io/2018/05/04/volatile-feature/

**3、AQS？**
**4、synchronized在静态方法和普通方法的区别？**

```markdown
普通方法锁当前实例对象，静态方法锁当前实例对象的类对象(Class)
```

**5、怎么实现所有线程在等待某个事件的发生才会去执行？**

​	countdownlatch和cyclicbarrier

- countdownlatch：阻塞主线程

  countdownlatch不可以重复使用，会阻塞主线程。主线程调用await方法，主线程阻塞。子线程调用countdown方法，触发计数。countdownlatch内部是实现了AQS，初始化的时候，new CountDownLatch(n);将AQS的state设置为n。

  await方法->acquireSharedInterruptibly->doAcquireSharedInterruptibly->shouldParkAfterFailedAcquire&parkAndCheckInterrupt->LockSupport.park.根据此调用链，会将当前线程阻塞。shouldParkAfterFailedAcquire方法相当于重新构造阻塞队列，对于前驱节点的waitstate大于0的删除，不是SIGNAL的赋值为SIGNAL。

  countdown是个解锁的过程，每个子线程执行一次countdown，state就减一，state等于0时，就会执行如下代码

- cyclicbarrier：阻塞子线程

  cyclicbarrier可以重复使用，它允许一组线程相互等待，直到达到某个公共屏障点。cyclicbarrier不会阻塞主线程，只会阻塞子线程。

  cyclicbarrier内部使用Lock，每一个子线程执行await，计数减一，当最后一个子线程的计数为0时，会执行cyclicbarrier构造函数中的Runable参数的run方法。

**6、CAS?CAS有什么缺陷，如何解决？**

> CAS（Compare-and-Swap），即比较并替换，是一种实现并发算法时常用到的技术
>
> CAS有缺陷，如ABA问题，自旋锁消耗问题、多变量共享一致性问题

- ABA：
  - 问题描述：线程t1将它的值从A变为B，再从B变为A。同时有线程t2要将值从A变为C。但CAS检查的时候会发现没有改变，但是实质上它已经发生了改变 。可能会造成数据的缺失
  - 解决方法：CAS还是类似于乐观锁，同数据乐观锁的方式给它加一个版本号或者时间戳，如AtomicStampedReference
- 自旋消耗资源：
  - 问题描述：多个线程争夺同一个资源时，如果自旋一直不成功，将会一直占用CPU
  - 解决方法：破坏掉for死循环，当超过一定时间或者一定次数时，return退出。JDK8新增的LongAddr,和ConcurrentHashMap类似的方法。当多个线程竞争时，将粒度变小，将一个变量拆分为多个变量，达到多个线程访问多个资源的效果，最后再调用sum把它合起来
- 多变量共享一致性问题
  - 问题描述：只能保证一个共享变量的原子操作
  - 解决方法： CAS操作是针对一个变量的，如果对多个变量操作，1. 可以加锁来解决。2 .封装成对象类解决

**7、synchronized 和 lock 有什么区别？**

1. 首先synchronized是java内置关键字，在jvm层面，Lock是个java类；
2. synchronized无法判断是否获取锁的状态，Lock可以判断是否获取到锁；
3. synchronized会自动释放锁(a 线程执行完同步代码会释放锁 ；b 线程执行过程中发生异常会释放锁)，Lock需在finally中手工释放锁（unlock()方法释放锁），否则容易造成线程死锁；
4. 用synchronized关键字的两个线程1和线程2，如果当前线程1获得锁，线程2线程等待。如果线程1阻塞，线程2则会一直等待下去，而Lock锁就不一定会等待下去，如果尝试获取不到锁，线程可以不用一直等待就结束了；
5. synchronized的锁可重入、不可中断、非公平，而Lock锁可重入、可判断、可公平（两者皆可）
6. Lock锁适合大量同步的代码的同步问题，synchronized锁适合代码少量的同步问题。

**8、Hashtable是怎么加锁的？**

```markdown
操作方法加了synchronized关键字
```

**9、HashMap,HashMap的并发问题？**

[https://www.jianshu.com/p/ee0de4c99f87](https://www.jianshu.com/p/ee0de4c99f87)

**10、1.8中为什么要用红黑树？**

​	提高检索效率，链表长度大于8（默认）时自动转化为红黑数，小于6（默认）时自动转化为链表

**11、ConcurrenHashMap介绍？** 

​	1.7中采用`Segment` + `HashEntry`的方式进行实现，其中`Segment`在实现上继承了`ReentrantLock`，这样就自带了锁的功能

​	1.8中放弃了`Segment`臃肿的设计，取而代之的是采用`Node` + `CAS` + `Synchronized`来保证并发安全进行实现

[https://www.jianshu.com/p/e694f1e868ec](https://www.jianshu.com/p/e694f1e868ec)

**12、如何检测死锁？怎么预防死锁？**

所谓死锁：是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁

死锁产生的原因？

1.因竞争资源发生死锁 现象：系统中供多个进程共享的资源的数目不足以满足全部进程的需要时，就会引起对诸资源的竞争而发生死锁现象

2.进程推进顺序不当发生死锁

死锁的四个必要条件：

（1）互斥条件：进程对所分配到的资源不允许其他进程进行访问，若其他进程访问该资源，只能等待，直至占有该资源的进程使用完成后释放该资源

（2）请求和保持条件：进程获得一定的资源之后，又对其他资源发出请求，但是该资源可能被其他进程占有，此事请求阻塞，但又对自己获得的资源保持不放

（3）不可剥夺条件：是指进程已获得的资源，在未完成使用之前，不可被剥夺，只能在使用完后自己释放

（4）环路等待条件：是指进程发生死锁后，必然存在一个进程--资源之间的环形链

处理死锁的基本方法

预防死锁（破坏四个必要条件）： 资源一次性分配：（破坏请求和保持条件）

可剥夺资源：即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）

资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反（破坏环路等待条件）

避免死锁（银行家算法）:

预防死锁的几种策略，会严重地损害系统性能。因此在避免死锁时，要施加较弱的限制，从而获得 较满意的系统性能。由于在避免死锁的策略中，允许进程动态地申请资源。因而，系统在进行资源分配之前预先计算资源分配的安全性。若此次分配不会导致系统进入不安全状态，则将资源分配给进程；否则，进程等待。其中最具有代表性的避免死锁算法是银行家算法。

 检测死锁

首先为每个进程和每个资源指定一个唯一的号码； 然后建立资源分配表和进程等待表，

 解除死锁

 当发现有进程死锁后，便应立即把它从死锁状态中解脱出来，常采用的方法有：

 剥夺资源：从其它进程剥夺足够数量的资源给死锁进程，以解除死锁状态；

撤消进程：可以直接撤消死锁进程或撤消代价最小的进程，直至有足够的资源可用，死锁状态.消除为止；所谓代价是指优先级、运行代价、进程的重要性和价值等。

避免一个线程同时获取多个锁 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。

通过jvisualvm查看产生死锁线程

**13、Java内存模型？**

> java内存模型(Java Memory Model，JMM)是java虚拟机规范定义的，用来屏蔽掉java程序在各种不同的硬件和操作系统对内存的访问的差异，这样就可以实现java程序在各种不同的平台上都能达到内存访问的一致性。可以避免像c++等直接使用物理硬件和操作系统的内存模型在不同操作系统和硬件平台下表现不同，比如有些c/c++程序可能在windows平台运行正常，而在linux平台却运行有问题
>
> https://www.jianshu.com/p/15106e9c4bf3

<img src="https://tva1.sinaimg.cn/large/006tNbRwly1g9n4dctroxj30uu0iwq7l.jpg" style="zoom: 50%;" />

- 在物理计算机中CPU为了提高处理速度，添加了高速缓存与CPU乱序执行
- Java定义了自身的内存模型是为了屏蔽掉不同硬件和操作系统的内存模型差异
- Java为了处理内存的不可见性与重排序的问题，定义了Happens-Before 原则
- Happens-Before 原则的理解：对于两个操作A和B，这两个操作可以在不同的线程中执行。如果A Happens-Before B，那么可以保证，当A操作执行完后，A操作的执行结果对B操作是可见的

**14、如何保证多线程下i++结果正确？**

synchronized

**15、线程池的种类，区别和使用场景？**

单、定量、缓存、定时任务

**16、分析线程池的实现原理和线程的调度过程？**

ThreadPoolExecutor

```java
// corePoolSize 核心线程数
// maximumPoolSize 最大工作线程数
// keepAliveTime 空闲线程存活时间
// workQueue 工作队列，存放任务
// RejectedExecutionHandler 拒绝策略
public ThreadPoolExecutor(int corePoolSize,
                              int maximumPoolSize,
                              long keepAliveTime,
                              TimeUnit unit,
                              BlockingQueue<Runnable> workQueue) {
 
        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
             Executors.defaultThreadFactory(), defaultHandler);
 

```

- 线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们
- 当调用 execute() 方法添加一个任务时，线程池会做如下判断
  - 如果正在运行的线程数量小于 corePoolSize，那么马上创建线程运行这个任务
  - 如果正在运行的线程数量大于或等于 corePoolSize，那么将这个任务放入队列
  - 如果这时候队列满了，而且正在运行的线程数量小于 maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务
  - 如果队列满了，而且正在运行的线程数量大于或等于 maximumPoolSize，那么线程池会执行拒绝策略
    - DiscardPolicy：不执行任何操作，直接丢弃任务
    - DiscardOldestPolicy：执行当前任务，丢弃最老的任务
    - AbortPolicy：抛出RejectedExecutionException，默认策略
    - CallerRunsPolicy：调用Runable的run方法，相当于执行一个普通方法

**17、线程池如何调优，最大数目如何确认？**

```markdown
对于线程池大小的设定，我们需要考虑的问题有：

CPU个数
内存大小
任务类型，是计算密集型（CPU密集型）还是I/O密集型
是否需要一些稀缺资源，像数据库连接这种等等
等等

有种简单的估算方式，设N为CPU个数
对于CPU密集型的应用，线程池的大小设置为N+1
对于I/O密集型的应用，线程池的大小设置为2N+1
这种设置方式适合于一台机器上的应用的类型是单一的，并且只有一个线程池，实际情况还需要根据实际的应用进行验证
```

**18、ThreadLocal原理，用的时候需要注意什么？**

[https://www.jianshu.com/p/0ba78fe61c40](https://www.jianshu.com/p/0ba78fe61c40)

**19、AQS**

https://www.jianshu.com/p/a372528f47a3

20、LockSupport工具

https://www.jianshu.com/p/d0e84096d108

21、Condition接口及其实现原理

https://www.jianshu.com/p/a22855b8820a

22、Fork/]oin框架的理解
23、分段锁的原理，锁力度减小的思考
24、八种阻塞队列以及合个阻塞队列的特性


